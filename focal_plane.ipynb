{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance as a function focal plane position\n",
    "\n",
    "Authors: Keith Bechtol and Angelo Fausti\n",
    "\n",
    "Date: 31 May 2018\n",
    "\n",
    "Stack Version: weekly 2018_21\n",
    "\n",
    "The goal of this notebook is to demonstrate methods to compile performance metrics from a set of individual visits and assemble as a function focal plane position (sensor number or x,y position in instrument coordinates). \n",
    "\n",
    "Unfortunately, it takes about a minute to read the `src` entries from a single visit, so it will take some patience to aggregate statistics from many visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lsst.daf.persistence as daf_persistence\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSC PDR1\n",
    "\n",
    "Information available here: https://confluence.lsstcorp.org/display/DM/S18+HSC+PDR1+reprocessing\n",
    "\n",
    "The output repos are:\n",
    "* /datasets/hsc/repo/rerun/DM-13666/UDEEP/\n",
    "* /datasets/hsc/repo/rerun/DM-13666/DEEP/\n",
    "* /datasets/hsc/repo/rerun/DM-13666/WIDE/\n",
    "\n",
    "Note that each of the data repositories contains all of the HSC visits, so one has to select by field to get the visits corresponding to a particular Strategic Survey Program (SSP) survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = 'HSC-R'\n",
    "depth = 'WIDE' # WIDE, DEEP, UDEEP\n",
    "field = 'SSP_WIDE'\n",
    "outfile = 'focal_plane_df.h5'\n",
    "butler = daf_persistence.Butler('/datasets/hsc/repo/rerun/DM-13666/%s/'%(depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, you can find out all of the SSP field names with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_visits = butler.queryMetadata('src', ['field'])\n",
    "[ field for field in unique_visits if 'SSP' in field ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_visits = butler.queryMetadata('src', ['visit'], dataId={'filter':band, 'field':field})\n",
    "print('Found %i unique visits in %s band %s depth survey'%(len(unique_visits), band, depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = butler.subset('src', dataId={'filter':band, 'field':field})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#butler.get('src', dataId=subset.cache[0]).schema.getNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over the individual visits and saving the columns of interest into a merged pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "restricted_columns = ['coord_ra','coord_dec',\n",
    "                      'slot_Centroid_x','slot_Centroid_y',\n",
    "                      'base_FPPosition_x', 'base_FPPosition_y',\n",
    "                      'slot_PsfFlux_flux',\n",
    "                      'slot_PsfShape_xx', 'slot_PsfShape_yy', 'slot_PsfShape_xy',\n",
    "                      'slot_Shape_xx', 'slot_Shape_yy', 'slot_Shape_xy',\n",
    "                      'calib_astrometryUsed',\n",
    "                      'calib_detected',\n",
    "                      'calib_photometry_reserved',\n",
    "                      'calib_photometry_used',\n",
    "                      'calib_psfCandidate',\n",
    "                      'calib_psfUsed',\n",
    "                      'calib_psf_reserved',\n",
    "                      'base_ClassificationExtendedness_value']\n",
    "\n",
    "if True:\n",
    "    df_array = [] \n",
    "    visits = unique_visits[0:1]\n",
    "    #visits = unique_visits[0:10]\n",
    "    for dataid in subset.cache:\n",
    "        if dataid['visit'] in visits and butler.datasetExists('src', dataid):\n",
    "            print(\"Loading Visit: {}, CCD: {}\".format(dataid['visit'], dataid['ccd']))\n",
    "            df_full = butler.get('src', dataid).asAstropy().to_pandas()\n",
    "            df = df_full[restricted_columns]\n",
    "            df['visit'] = dataid['visit']\n",
    "            df['ccd'] = dataid['ccd']\n",
    "            df_array.append(df)\n",
    "\n",
    "    df = pd.concat(df_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this merged pandas dataframe to an HDF5 file, so we don't have to re-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_hdf(outfile, 'df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortcut is to read the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_hdf(outfile, 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(list(df.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some measures of image quality, such as PSF sizes and ellipticities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = df.slot_PsfShape_xx\n",
    "yy = df.slot_PsfShape_yy\n",
    "xy = df.slot_PsfShape_xy\n",
    "df['psf_trace_radius'] = np.sqrt((xx + yy) / 2.)\n",
    "df['psf_determinant_radius'] = (xx * yy - xy * xy)**(1. / 4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipticity(I_xx, I_xy, I_yy):\n",
    "    \"\"\"Calculate ellipticity from second moments.\n",
    "    Parameters\n",
    "    ----------\n",
    "    I_xx : float\n",
    "    I_xy : float\n",
    "    I_yy : float\n",
    "    Returns\n",
    "    -------\n",
    "    e, e1, e2 : (float, float, float) or (numpy.array, numpy.array, numpy.array)\n",
    "        Complex ellipticity, real component, imaginary component\n",
    "    \"\"\"\n",
    "\n",
    "    #e = (I_xx - I_yy + 2j*I_xy) / (I_xx + I_yy + 2*np.sqrt(I_xx*I_yy - I_xy*2))\n",
    "    e = (I_xx - I_yy + 2j*I_xy) / (I_xx + I_yy + 2*np.sqrt(I_xx*I_yy - I_xy**2))\n",
    "    e1 = e.real\n",
    "    e2 = e.imag\n",
    "    return e, e1, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restricted_columns = ['']\n",
    "#sources_df.query(cut)[restricted_columns]\n",
    "df_stars = df.query('base_ClassificationExtendedness_value == 0')\n",
    "#df_stars = df.query('calib_psf_reserved == 1')\n",
    "print(len(df_stars))\n",
    "print(len(df_stars.slot_Shape_xx))\n",
    "e, e1, e2 = ellipticity(df_stars.slot_Shape_xx, df_stars.slot_Shape_xy, df_stars.slot_Shape_yy)\n",
    "df_stars['e1'] = e1\n",
    "df_stars['e2'] = e2\n",
    "\n",
    "e, e1, e2 = ellipticity(df_stars.slot_PsfShape_xx, df_stars.slot_PsfShape_xy, df_stars.slot_PsfShape_yy)\n",
    "df_stars['e1_psf'] = e1\n",
    "df_stars['e2_psf'] = e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#c = df.ccd\n",
    "#c = df.base_PixelFlags_flag_edge\n",
    "c = df.psf_trace_radius\n",
    "plt.scatter(df.base_FPPosition_x, df.base_FPPosition_y, c=c, edgecolor='none', marker='.', s=1)\n",
    "plt.colorbar(label='CCD')\n",
    "plt.xlabel('Focal Plane X')\n",
    "plt.xlabel('Focal Plane Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "c = df_stars.e1 - df_stars.e1_psf\n",
    "plt.scatter(df_stars.base_FPPosition_x, df_stars.base_FPPosition_y, c=c, \n",
    "            edgecolor='none', marker='.', s=1, cmap='coolwarm', vmin=-0.1, vmax=0.1)\n",
    "plt.colorbar(label='CCD')\n",
    "plt.xlabel('Focal Plane X')\n",
    "plt.xlabel('Focal Plane Y')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(c, bins=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to bin the performance metrics by instrument coordinates to more easily visualize sublte variations over the focal plane. The cell below performs a simple average each each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-20000, 20000, 401)\n",
    "counts = np.histogram2d(df.base_FPPosition_x, df.base_FPPosition_y, bins=[bins, bins])[0]\n",
    "weights = np.histogram2d(df.base_FPPosition_x, df.base_FPPosition_y, bins=[bins, bins], weights=df.psf_trace_radius)[0]\n",
    "mean = (weights / counts).T\n",
    "plt.figure()\n",
    "plt.imshow(mean, extent=(bins[0], bins[-1], bins[0], bins[-1]), origin='lower')\n",
    "plt.colorbar().set_label('PSF Trace Radius')\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.ylim(bins[0], bins[-1])\n",
    "plt.xlabel('Focal Plane X')\n",
    "plt.xlabel('Focal Plane Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-20000, 20000, 101)\n",
    "z = df_stars.e1 - df_stars.e1_psf\n",
    "#z = df_stars.e2\n",
    "counts = np.histogram2d(df_stars.base_FPPosition_x, df_stars.base_FPPosition_y, bins=[bins, bins])[0]\n",
    "weights = np.histogram2d(df_stars.base_FPPosition_x, df_stars.base_FPPosition_y, bins=[bins, bins], \n",
    "                         weights=z)[0]\n",
    "mean = (weights / counts).T\n",
    "plt.figure()\n",
    "plt.imshow(mean, extent=(bins[0], bins[-1], bins[0], bins[-1]), origin='lower', vmin=-0.05, vmax=0.05, cmap='coolwarm')\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.ylim(bins[0], bins[-1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is work in progress (something is clearly wrong). Still learning how to make a whisker plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-20000, 20000, 41)\n",
    "X, Y = np.meshgrid(bins, bins)\n",
    "\n",
    "counts = np.histogram2d(df_stars.base_FPPosition_x, df_stars.base_FPPosition_y, bins=[bins, bins])[0]\n",
    "weights = np.histogram2d(df_stars.base_FPPosition_x, df_stars.base_FPPosition_y, bins=[bins, bins], \n",
    "                         weights=df_stars.e1_psf)[0]\n",
    "U = (weights / counts).T\n",
    "\n",
    "counts = np.histogram2d(df_stars.base_FPPosition_x, df_stars.base_FPPosition_y, bins=[bins, bins])[0]\n",
    "weights = np.histogram2d(df_stars.base_FPPosition_x, df_stars.base_FPPosition_y, bins=[bins, bins], \n",
    "                         weights=df_stars.e2_psf)[0]\n",
    "V = (weights / counts).T\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "#q = plt.quiver(X, Y, U, V, color=np.sqrt(U**2 + V**2), pivot='middle', angles='uv', headwidth=0)\n",
    "q = plt.quiver(X, Y, U, V, pivot='middle', angles='uv', headwidth=0)\n",
    "#plt.quiverkey(q, X=0.3, Y=1.1, U=10,\n",
    "#             label='Quiver key, length = 10', labelpos='E')\n",
    "\n",
    "plt.show()\n",
    "help(plt.quiver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Scraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#subset = butler.subset('calexp', **{'filter':band, 'visit':unique_visits[0]})\n",
    "#for ii in range(0, len(subset.cache)):\n",
    "#    src = butler.get('src', **subset.cache[ii])\n",
    "#butler.queryMetadata('calexp', ['visit', 'ccd', 'filter'], dataId={'filter':band, 'visit':unique_visits[0]})\n",
    "\n",
    "n_visits = 2\n",
    "df_array = []\n",
    "for ii in range(0, n_visits):\n",
    "    print('Visit = %i'%(unique_visits[ii]))\n",
    "    df_array.append(getSrcFullFocalPlane(unique_visits[ii], band))\n",
    "    #src = butler.get('src', dataId={'visit':unique_visits[ii], 'filter':band, 'ccd':0})\n",
    "    \n",
    "df = pd.concat(df_array)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def getSrcFullFocalPlane(visit, band):\n",
    "    subset = butler.subset('src', **{'filter':band, 'visit':visit})\n",
    "    #print(len(subset.cache))\n",
    "    df_array =[]\n",
    "    for dataid in subset.cache:\n",
    "        if butler.datasetExists('src', dataId=dataid):\n",
    "            #print('It exists:', dataid['ccd'])\n",
    "            src = butler.get('src', dataId=dataid)\n",
    "            df_array.append(src.asAstropy().to_pandas())\n",
    "            #data = {'x': src.getX(),\n",
    "            #        'y': src.getY()}\n",
    "            #df_array.append(pd.DataFrame(data=data))\n",
    "            #df_array[-1] = df_array[-1].assign(visit = dataid['visit'])\n",
    "            #df_array[-1] = df_array[-1].assign(ccd = dataid['ccd'])\n",
    "            df_array[-1]['visit'] = dataid['visit']\n",
    "            df_array[-1]['ccd'] = dataid['ccd']\n",
    "        else:\n",
    "            pass\n",
    "            #print('No go:', dataid['ccd'])\n",
    "            \n",
    "    return pd.concat(df_array)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
