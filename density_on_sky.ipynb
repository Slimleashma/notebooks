{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import multiprocessing as mproc\n",
    "from lsst.daf.persistence import Butler\n",
    "repo_dir = '/datasets/hsc/repo/rerun/DM-13666/WIDE'\n",
    "butler = Butler(repo_dir)\n",
    "#/datasets/hsc/repo/rerun/DM-13666/DEEP/deepCoadd-results/HSC-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_counts(butler, catalog_name, dataId_list, nside,\n",
    "                     i_process, out_dict):\n",
    "    \"\"\"\n",
    "    Takes a butler and a list of dataIds and figurs out how many\n",
    "    stars appear in each healpix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    butler -- an instance of lsst.daf.persistence.Butler\n",
    "    \n",
    "    catalog_name -- the dataset to query (i.e. 'deepCoadd_ref')\n",
    "    \n",
    "    dataId_list -- a list of dataIds to process\n",
    "    \n",
    "    nside -- the nside of the healpixel grid\n",
    "    \n",
    "    i_process -- a unique identifier for this process as called\n",
    "    from multiprocessing\n",
    "    \n",
    "    out_dict -- a multiprocessing.Manager().dict() where we will\n",
    "    store the output\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Nothing\n",
    "    \n",
    "    A numpy array corresponding to the number of stars in each\n",
    "    healpixel is stored in out_dict[i_process]\n",
    "    \"\"\"\n",
    "    \n",
    "    npix = hp.nside2npix(nside)\n",
    "    pixel_counts = np.zeros(npix, dtype=int)\n",
    "    ct = 0\n",
    "    t_start = time.time()\n",
    "    for dataId in dataId_list:\n",
    "        ref_cat = butler.get(catalog_name, dataId=dataId)\n",
    "        is_primary = ref_cat['detect_isPrimary']\n",
    "        is_star = ref_cat['base_ClassificationExtendedness_value'] < 0.99\n",
    "        valid = is_primary & is_star\n",
    "        data = ref_cat[valid]\n",
    "        pixel_number = hp.ang2pix(nside,\n",
    "                                  np.degrees(data['coord_ra']),\n",
    "                                  np.degrees(data['coord_dec']),\n",
    "                                  lonlat=True)\n",
    "\n",
    "        l_pixel_dexes, l_pixel_counts = np.unique(pixel_number,\n",
    "                                                  return_counts=True)\n",
    "        pixel_counts[l_pixel_dexes]+=l_pixel_counts\n",
    "        ct += 1\n",
    "        if ct %10 ==0:\n",
    "            duration = time.time()-t_start\n",
    "            predict = len(dataId_list)*duration/ct\n",
    "            print('ran %d of %d dataIds; took %.2e sec; total should take %.2e hrs' %\n",
    "                  (ct, len(dataId_list), duration, predict/3600.0))\n",
    "    out_dict[i_process] = pixel_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolution 1.311396e-02 sq degrees\n"
     ]
    }
   ],
   "source": [
    "nside = 512\n",
    "npix = hp.nside2npix(nside)\n",
    "print('resolution %e sq degrees' % (4.0*np.pi*(180.0/np.pi)**2/npix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_counts = np.zeros(npix, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_map = butler.get('deepCoadd_skyMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_name = 'deepCoadd_forced_src'\n",
    "ref_name = 'deepCoadd_ref'\n",
    "filter_name = 'HSC-R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_root = os.path.join(repo_dir, 'deepCoadd-results', filter_name)\n",
    "tract_list = os.listdir(tract_root)\n",
    "tract_list = np.array(tract_list).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_id = []\n",
    "for tract_id in tract_list:\n",
    "    tract = sky_map[tract_id]\n",
    "    patches = tract.getNumPatches()\n",
    "    for ip1 in range(patches[0]):\n",
    "        for ip2 in range(patches[1]):\n",
    "            dataId = {'filter':filter_name,\n",
    "                      'tract':tract_id,\n",
    "                      'patch':'%d,%d' % (ip1, ip2)}\n",
    "            if not butler.datasetExists(catalog_name, dataId=dataId):\n",
    "                continue\n",
    "            else:\n",
    "                valid_data_id.append(dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6965\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "print(len(valid_data_id))\n",
    "valid_data_id_true = copy.deepcopy(valid_data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_frac 100 len 400\n",
      "0 100 100\n",
      "100 200 100\n",
      "200 300 100\n",
      "300 400 100\n",
      "ran 10 of 100 dataIds; took 3.06e+01 sec; total should take 8.51e-02 hrs\n",
      "ran 10 of 100 dataIds; took 3.56e+01 sec; total should take 9.89e-02 hrs\n",
      "ran 10 of 100 dataIds; took 3.58e+01 sec; total should take 9.93e-02 hrs\n",
      "ran 10 of 100 dataIds; took 4.07e+01 sec; total should take 1.13e-01 hrs\n",
      "ran 20 of 100 dataIds; took 7.50e+01 sec; total should take 1.04e-01 hrs\n",
      "ran 20 of 100 dataIds; took 7.70e+01 sec; total should take 1.07e-01 hrs\n",
      "ran 20 of 100 dataIds; took 8.31e+01 sec; total should take 1.15e-01 hrs\n",
      "ran 20 of 100 dataIds; took 8.33e+01 sec; total should take 1.16e-01 hrs\n",
      "ran 30 of 100 dataIds; took 1.24e+02 sec; total should take 1.15e-01 hrs\n",
      "ran 30 of 100 dataIds; took 1.27e+02 sec; total should take 1.17e-01 hrs\n",
      "ran 30 of 100 dataIds; took 1.31e+02 sec; total should take 1.21e-01 hrs\n",
      "ran 30 of 100 dataIds; took 1.34e+02 sec; total should take 1.24e-01 hrs\n",
      "ran 40 of 100 dataIds; took 1.62e+02 sec; total should take 1.13e-01 hrs\n",
      "ran 40 of 100 dataIds; took 1.65e+02 sec; total should take 1.14e-01 hrs\n",
      "ran 40 of 100 dataIds; took 1.65e+02 sec; total should take 1.15e-01 hrs\n",
      "ran 40 of 100 dataIds; took 1.69e+02 sec; total should take 1.17e-01 hrs\n",
      "ran 50 of 100 dataIds; took 1.98e+02 sec; total should take 1.10e-01 hrs\n",
      "ran 50 of 100 dataIds; took 2.04e+02 sec; total should take 1.13e-01 hrs\n",
      "ran 50 of 100 dataIds; took 2.04e+02 sec; total should take 1.13e-01 hrs\n",
      "ran 50 of 100 dataIds; took 2.08e+02 sec; total should take 1.15e-01 hrs\n",
      "ran 60 of 100 dataIds; took 2.39e+02 sec; total should take 1.11e-01 hrs\n",
      "ran 60 of 100 dataIds; took 2.41e+02 sec; total should take 1.12e-01 hrs\n",
      "ran 60 of 100 dataIds; took 2.49e+02 sec; total should take 1.15e-01 hrs\n",
      "ran 60 of 100 dataIds; took 2.51e+02 sec; total should take 1.16e-01 hrs\n",
      "ran 70 of 100 dataIds; took 2.76e+02 sec; total should take 1.09e-01 hrs\n",
      "ran 70 of 100 dataIds; took 2.83e+02 sec; total should take 1.12e-01 hrs\n",
      "ran 70 of 100 dataIds; took 2.88e+02 sec; total should take 1.14e-01 hrs\n",
      "ran 70 of 100 dataIds; took 2.89e+02 sec; total should take 1.15e-01 hrs\n",
      "ran 80 of 100 dataIds; took 3.09e+02 sec; total should take 1.07e-01 hrs\n",
      "ran 80 of 100 dataIds; took 3.12e+02 sec; total should take 1.08e-01 hrs\n",
      "ran 80 of 100 dataIds; took 3.20e+02 sec; total should take 1.11e-01 hrs\n",
      "ran 80 of 100 dataIds; took 3.23e+02 sec; total should take 1.12e-01 hrs\n",
      "ran 90 of 100 dataIds; took 3.42e+02 sec; total should take 1.06e-01 hrs\n",
      "ran 90 of 100 dataIds; took 3.46e+02 sec; total should take 1.07e-01 hrs\n",
      "ran 90 of 100 dataIds; took 3.55e+02 sec; total should take 1.10e-01 hrs\n",
      "ran 90 of 100 dataIds; took 3.65e+02 sec; total should take 1.13e-01 hrs\n",
      "ran 100 of 100 dataIds; took 3.79e+02 sec; total should take 1.05e-01 hrs\n",
      "ran 100 of 100 dataIds; took 3.81e+02 sec; total should take 1.06e-01 hrs\n",
      "ran 100 of 100 dataIds; took 3.87e+02 sec; total should take 1.08e-01 hrs\n",
      "ran 100 of 100 dataIds; took 4.01e+02 sec; total should take 1.11e-01 hrs\n"
     ]
    }
   ],
   "source": [
    "nside = 512\n",
    "n_proc = 4\n",
    "valid_data_id = copy.deepcopy(valid_data_id_true)\n",
    "manager = mproc.Manager()\n",
    "pixel_dict = manager.dict()\n",
    "\n",
    "# just take a random subset\n",
    "valid_data_id = np.array(valid_data_id)\n",
    "rng = np.random.RandomState(9912)\n",
    "rng.shuffle(valid_data_id)\n",
    "valid_data_id = valid_data_id[:400]\n",
    "\n",
    "valid_id_arr = []\n",
    "butler_arr = []\n",
    "\n",
    "n_frac = len(valid_data_id)//n_proc\n",
    "\n",
    "print('n_frac %d len %d' % (n_frac,len(valid_data_id)))\n",
    "\n",
    "for ii in range(n_proc):\n",
    "    i_start = ii*n_frac\n",
    "    i_end = (ii+1)*n_frac\n",
    "    if ii == n_proc-1:\n",
    "        i_end=len(valid_data_id)\n",
    "    local_id_list = valid_data_id[i_start:i_end]\n",
    "    print(i_start,i_end,len(local_id_list))\n",
    "    valid_id_arr.append(local_id_list)\n",
    "    butler_arr.append(Butler(repo_dir))\n",
    "\n",
    "    #butler, catalog_name, dataId_list, nside,\n",
    "    #                 i_process, out_dict\n",
    "    \n",
    "job_list = []\n",
    "for ii in range(n_proc):\n",
    "    p = mproc.Process(target=get_pixel_counts,\n",
    "                      args=(butler_arr[ii],\n",
    "                            'deepCoadd_ref',\n",
    "                            valid_id_arr[ii],\n",
    "                            nside, ii, pixel_dict))\n",
    "\n",
    "    p.start()\n",
    "    job_list.append(p)\n",
    "\n",
    "for p in job_list:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_cat = butler.get(ref_name, dataId=valid_data_id[0])\n",
    "src_cat = butler.get(catalog_name, dataId=valid_data_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ref_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(src_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(ref_cat['coord_ra'], src_cat['coord_ra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(ref_cat['coord_dec'], src_cat['coord_dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_cat['detect_isPrimary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_cat.schema.find('base_PsfFlux_flux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src_cat.schema.getNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_val = src_cat['base_ClassificationExtendedness_value']\n",
    "ref_val = ref_cat['base_ClassificationExtendedness_value']\n",
    "flux_flag = ref_cat['modelfit_CModel_flag']\n",
    "src_psf_flux = src_cat['base_PsfFlux_flux']\n",
    "src_model_flux = src_cat['modelfit_CModel_flux']\n",
    "ref_psf_flux = ref_cat['base_PsfFlux_flux']\n",
    "ref_model_flux =ref_cat['modelfit_CModel_flux']\n",
    "\n",
    "src_ratio = src_psf_flux/src_model_flux\n",
    "ref_ratio = ref_psf_flux/ref_model_flux\n",
    "for ii in range(len(src_cat)):\n",
    "    if src_val[ii] != ref_val[ii] and not np.isnan(src_val[ii]) and \\\n",
    "    not np.isnan(ref_val[ii]):\n",
    "        print(src_val[ii], ref_val[ii],\n",
    "              src_ratio[ii], ref_ratio[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hp.ang2pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "ct = 0\n",
    "pixel_counts = np.zeros(npix, dtype=float)\n",
    "t_start = time.time()\n",
    "for dataId in valid_data_id:\n",
    "    ref_cat = butler.get(ref_name, dataId=dataId)\n",
    "    is_primary = ref_cat['detect_isPrimary']\n",
    "    is_star = ref_cat['base_ClassificationExtendedness_value'] < 0.99\n",
    "    valid = is_primary & is_star\n",
    "    data = ref_cat[valid]\n",
    "    pixel_number = hp.ang2pix(nside,\n",
    "                              np.degrees(data['coord_ra']),\n",
    "                              np.degrees(data['coord_dec']),\n",
    "                              lonlat=True)\n",
    "\n",
    "    l_pixel_dexes, l_pixel_counts = np.unique(pixel_number,\n",
    "                                              return_counts=True)\n",
    "    pixel_counts[l_pixel_dexes]+=l_pixel_counts\n",
    "    ct += 1\n",
    "    if ct %10 ==0:\n",
    "        duration = time.time()-t_start\n",
    "        predict = len(valid_data_id)*duration/ct\n",
    "        print('ran %d of %d dataIds; took %e sec; total should take %e sec' %\n",
    "              (ct, len(valid_data_id), duration, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pixels = np.where(pixel_counts>0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_arr, dec_arr = hp.pix2ang(nside, range(len(pixel_counts)),lonlat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ra = ra_arr[valid_pixels]\n",
    "valid_dec = dec_arr[valid_pixels]\n",
    "valid_counts = pixel_counts[valid_pixels]\n",
    "\n",
    "ra_min = valid_ra.min()\n",
    "ra_max = valid_ra.max()\n",
    "dec_min = valid_dec.min()\n",
    "dec_max = valid_dec.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ra_min,ra_max)\n",
    "print(dec_min,dec_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figsize=(30,30)\n",
    "\n",
    "plt.scatter(valid_ra, valid_dec, c=valid_counts)\n",
    "plt.xlabel('ra')\n",
    "plt.ylabel('dec')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_view = hp.mollview(pixel_counts, cbar=False,\n",
    "                        #lonra=[ra_min,ra_max],\n",
    "                        #latra=[dec_min,dec_max],\n",
    "                        flip='astro',\n",
    "                        return_projected_map=True)\n",
    "\n",
    "\n",
    "plt.imshow(cart_view, extent=[ra_min, ra_max, dec_min, dec_max],\n",
    "           origin='lower', interpolation='none')\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "plt.xlabel('ra')\n",
    "ax.set_ylabel('dec')\n",
    "xticks = np.arange(ra_min, ra_max, 0.1*(ra_max-ra_min))\n",
    "print(cart_view.shape)\n",
    "print(cart_view.shape[0]*cart_view.shape[1], npix)\n",
    "print(cart_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(pixel_counts, cbar=False,\n",
    "                        flip='astro',\n",
    "                        return_projected_map=True)\n",
    "hp.graticule()\n",
    "ax = plt.gca()\n",
    "im = ax.get_images()[0]\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pixel_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(pixel_counts[valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(hp.gnomview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hp.projaxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.nside2npix(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hp.graticule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
